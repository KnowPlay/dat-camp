---
title: "Data Manipulation with dplyr"
output:
  html_document: default
date: "2023-01-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Part 1. Transforming Data with dplyr

### 1. Exploring data with dplyr

```{}
1. Exploring data with dplyr
Hi! We'll discover dplyr's power for exploring, transforming, and aggregating data.

2. The dplyr package
The dplyr package is one of several packages included in the Tidyverse collection. dplyr provides a ton of functionality to quickly manipulate and transform datasets. dplyr can be installed on its own, or with the other Tidyverse packages by installing tidyverse.

1 Wickham H, Averick M, Bryan J, Chang W, McGowan LD, FranÃ§ois R, Grolemund G, et al. (2019). "Welcome to the tidyverse." Journal of Open Source Software, 4(43), 1686. doi:10.21105/joss.01686.
3. Chapter 1 verbs
In this chapter, you'll learn to use four dplyr verbs to explore and transform a dataset. The four verbs are select(), filter(), arrange(), and mutate(). By the end of this chapter, you'll be comfortable using these verbs in various combinations.

4. 2015 United States Census
Throughout this course, we'll work with a real dataset, where you'll not only be able to practice the dplyr transformation verbs but also learn how to explore and draw insights from data. This particular dataset is from the 2015 United States Census.

5. United States counties
A state is one of 50 regions within the United States, such as New York, California, or Texas. A county is a subregion of one of those states, like Los Angeles county in California.

6. counties dataset
The US census data at the county-level has been loaded in the counties tibble, which we can access by typing counties into the console. This dataset contains loads of information, but don't worry, we're only going to work with a few variables, or columns, at a time! This table includes information about people living in each county, such as the population, the unemployment rate, their income, and demographic information, so there are a lot of interesting questions we can answer with this data. There are 40 variables in the counties dataset, and only the first few are previewed in the tibble.

7. glimpse()
The glimpse() function can be used to view the first few values from each variable, along with the data type, which is a useful first step in understanding the data.

8. select() verb
Datasets often come with more variables than we need, and we're not going to need all of them in any one analysis. Let's keep only a few variables: the state, the county, the total population, and the unemployment rate. We can do this using the select() verb. select() extracts only particular variables from a dataset. Using dplyr syntax, we can type counties, then the pipe operator, which is two percent signs with a greater-than arrow in between. Then, we select the variables of interest by calling the select function, and passing the variable names separated by commas. The output contains only the variables we passed to select().

9. Creating a new table
Sometimes, we want to keep the data we've selected for use further down the line. We can use assignment to store this new table. Recall that we assign objects to variables using the arrow operator, written as "less than dash".

10. Printing the dataset
This new table, counties-underscore-selected, can now be accessed or used. We can print that dataset just as we did the first one.

11. %>%
It provides a mechanism for chaining commands with a new forward-pipe operator, %>%. This operator will forward a value, or the result of an expression, into the next function call/expression
```

### 2. Understanding your data

```{}
Take a look at the counties dataset using the glimpse() function.

What is the first value in the income variable?
A. 1001
-> B. 51281
C. 50254
D. 40725
```

### 3. Selecting columns

```{p1-3}
counties %>%
  # Select the columns
  select(state, county, population, poverty)
```

### 4. The filter and arrange verbs

```{}
1. The filter and arrange verbs
We've seen how the select verb can be used to select particular variables, or columns, from a dataset. Now we'll explore the data to find interesting observations, or rows.

2. Selecting columns
We start with code for selecting four columns of interest: the state, county, population, and unemployment rate. We could start by assigning that to the variable counties-underscore-selected. We'll work with that variable from now on. Right now, notice that the observations are in alphabetical order by state and county.

3. arrange()
We might instead be interested in the counties that have the highest population. The arrange() verb sorts your data based on one or more variables. We start with the counties_selected variable, then the pipe operator to feed the result into arrange. Inside the arrange parentheses, we specify the variable to sort by, population in this case. This shows us the counties with the lowest population, which are indeed pretty small: one county in Hawaii has only 85 people.

4. desc()
We might be more interested in the counties with the highest population. To find these, we'd change our code only a little bit: wrapping the desc() around population. It looks like the highest population is Los Angeles, California, which is one of the biggest cities in the United States. Arrange is thus a useful verb for finding the most interesting observations in a dataset.

5. filter()
Another useful verb is filter(). We can use the filter verb to extract only particular observations from a dataset, based on a condition. Recall that after your first verb, we can add a pipe operator, then add another verb. We can pipe any number of verbs together to transform a dataset in a series of steps. For example, after the arrange(), we could add filter state equals equals quote New York to get only counties in the state of New York. Notice that the observations are filtered, but they're still sorted by population thanks to arrange.

6. filter()
Besides equals equals, we can filter based on logical operators like less than or greater than. For example, we could filter for counties that have an unemployment rate of less than 6 percent. The condition in the filter would be unemployment less than 6. This tells us that the largest counties with an unemployment rate below 6 percent are Fairfax, Virginia and Salt Late, Utah.

7. Combining conditions
Finally, we can combine multiple conditions together in a filter. We've filtered for the state of New York and for unemployment below 6 percent, but we can do both at the same time by separating them with a comma. It looks like only a few counties in New York have an unemployment rate that low.
```

### 5. Arranging observations

```{p1-5}
counties_selected <- counties %>%
  select(state, county, population, private_work, public_work, self_employed)

counties_selected %>%
  # Add a verb to sort in descending order of public_work
  arrange(desc(public_work)) 
```

### 6. Filtering for conditions

```{p1-6}
counties_selected <- counties %>%
  select(state, county, population)

counties_selected %>%
  # Filter for counties with a population above 1000000
  filter(population > 1000000) 

counties_selected %>%
  # Filter for counties with a population above 1000000
  filter(state == "California", population > 1000000)
```

### 7. Filtering and arranging

```{p1-7}
counties_selected <- counties %>%
  select(state, county, population, private_work, public_work, self_employed)

# Filter for Texas and more than 10000 people; sort in descending order of private_work
counties_selected %>%
  # Filter for Texas and more than 10000 people
  filter(state == "Texas", population > 10000) %>%
  # Sort in descending order of private_work
  arrange(desc(private_work)) 
```

### 8. The mutate() verb

```{}
1. The mutate() verb
Datasets don't always have the variables we need. We can use the mutate() verb to add new variables or change existing variables.

2. Selecting columns
Let's start with a dataset where we've selected four interesting variables: state, county, population, and unemployment. The unemployment rate is given as a percentage, so 5 would mean 5 percent, or one twentieth.

3. Total number of unemployed people
What if we were interested in the total number of unemployed people in a county, rather than as a percentage of the population? We could use the formula population times unemployment divided by 100.

4. mutate()
We use the mutate() verb to calculate this variable and add it to the dataset as a new variable, which we'll name unemployed-underscore-population. We pipe from counties_selected, then call mutate on our unemployed population formula. Notice that the new dataset has the variable unemployed population added to it. We got to choose the name of this variable by putting unemployed-underscore-population before the equals sign.

5. mutate() and arrange()
We can combine this new variable with other verbs to answer more questions with our data. For example, which counties have the highest number of unemployed people? We'd add arrange desc unemployed-underscore-population after the mutate.
```

### 9. Calculating the number of government employees

```{p1-9}
counties_selected <- counties %>%
  select(state, county, population, public_work)

counties_selected %>%
  # Add a new column public_workers with the number of people employed in public work
  mutate(public_workers = population * public_work/100) 

counties_selected %>%
  mutate(public_workers = public_work * population / 100) %>%
  # Sort in descending order of the public_workers column
  arrange(desc(public_workers))
```

### 10. Calculating the percentage of women in a county

```{p1-10}
counties_selected <- counties %>%
  # Select the columns state, county, population, men, and women
  select(state, county, population, men, women)

counties_selected %>%
  # Calculate proportion_women as the fraction of the population made up of women
mutate(proportion_women = women/population) 
```

### 11. Select, mutate, filter, and arrange

```{p1-11}
counties %>%
  # Select the five columns 
  select(state, county, population, men, women) %>%
  # Add the proportion_men variable
  mutate(proportion_men = men / population)%>%
  # Filter for population of at least 10,000
  filter(population >= 10000) %>%
  # Arrange proportion of men in descending order 
  arrange(desc(proportion_men)) 
```

## Part 2. Aggregating Data

### 1. The count verb

```{}
1. The count verb
So far in this course, we've learned to select variables from a dataset, to filter and sort observations, and to create new variables with the mutate verb. But, so far, we've been working at the same level as the initial data, where every observation corresponds to one US county. In this chapter, you'll learn to aggregate data, that is, to take many observations and summarize them into one. This is a common strategy for making datasets manageable and interpretable.

2. Count
One way we can aggregate data is to count it: to find out the number of observations. The dplyr verb for this is count(). The result is a table with one row and one column, called n. This tells us there are 3,138 observations in the table, or counties in the United States.

3. Count variable
Counting the total number of observations can be useful, but the real value of the verb is when we give it a specific variable to count. For example, we could count the number of counties in each state by passing the state variable to count(). Notice that the resulting table has 50 observations: one for each of the 50 states. We've aggregated more than three thousand observations into a more manageable number. The second column, n, tells us that there are 67 counties in Alabama, 28 in Alaska, and so on.

4. Count and sort
When we explore datasets, we're often interested in sorting the counted data to find the most common observations. The count verb takes a second argument, sort, that allows us to do just that. We can add comma sort equals TRUE, and the resulting rows will be sorted from the most common observations to the least. This tells us that Texas is the state with the most counties, followed by Georgia and Virginia.

5. Count population
Finally, when we're adding up counties, we may want to weigh each of them differently. For example, recall that our counties dataset has a column called population. What if instead of finding the number of counties in each state, we wanted to know the total number of people in each state?

6. Add weight
We can add the argument wt, which stands for "weight", equals population. This means that the n column will be weighted by the population. In the result, instead of seeing the number of counties in each state, we see the total population. Here we can see that California is the US state with the highest population, followed by Texas.
```

### 2. Counting by region

```{p2-2}
# Use count to find the number of counties in each region
counties_selected %>%
  count(region, sort = TRUE)
```

### 3. Counting citizens by state

```{p2-3}
# Find number of counties per state, weighted by citizens, sorted in descending order
counties_selected %>%
  count(state, sort = TRUE, wt = citizens)
```

### 4. Mutating and counting

```{p2-4}
counties_selected %>%
  # Add population_walk containing the total number of people who walk to work 
  mutate(population_walk = population * walk/100) %>%
  # Count weighted by the new column, sort in descending order
  count(state, wt = population_walk, sort = TRUE) 
```

### 5. The group_by, summarize, and ungroup verbs

```{}
1. The group_by, summarize, and ungroup verbs
We've learned about to aggregate data using the count() verb, but count() is a special case of a more general set of verbs: group_by and summarize.

2. Summarize
The summarize verb takes many observations and turns them into one observation. If we wanted to find the total population of the United States, we could use the summarize() verb. We provide the a new variable name for this total, total-underscore-population, and set it equal to the sum of the population.

3. Aggregate and summarize
We can define multiple variables in a summarize call, and aggregate each in different ways. For example, we could find the total population and the average unemployment rate, using the mean() function in this case.

4. Summary functions
There are other summary functions we can use in summarize(), such as median(), min() for minimum, max() for maximum, and n() for the size of the group. We could combine these to find summaries like the highest average income of any county, the median percentage that drives to work, or the average income level.

5. Aggregate within groups
Summarizing the entire table is useful, but, ideally, we want to aggregate within groups, such as finding the total population within each state, or the average unemployment. We can achieve this by piping first into group_by(), and choosing the variable to group on, state, then piping from that into summarize(). The result is the total population and average unemployment for each state.

6. Sorting summaries
It's useful to add an additional step that sorts the results, so that we can focus on the most notable examples. We could sort the results by average unemployment in descending order by nesting the desc() function inside arrange(). This tells us that Mississippi is the state with the highest unemployment.

7. Metro column
Finally, we can group by multiple columns at the same time. The dataset also includes a metro column, which describes whether the county is a metro area- that is, a city- or nonmetro.

8. Grouping on multiple columns
We can group by both columns by passing both column names to group_by. This will result in one row for each combination of state and metro. Instead of 50 observations in the output, we have 97, since a few states don't have any counties that aren't metro areas. For instance, here we see that the total population in Alabama metro areas is 3-point-6 million, and the population in nonmetro areas is 1-point-2 million. Notice that the result is still grouped by state: you can see "Groups: state" at the top of the table. When you use summarize on a table that has multiple groups, only the last group gets "peeled off". This is useful when you want to continue doing additional summaries or aggregations.

9. Ungroup
If you don't want to keep state as a group, you can add another dplyr verb: ungroup(). 
```

### 6. Summarizing

```{p2-6}
counties_selected %>%
  # Summarize to find minimum population, maximum unemployment, and average income
  summarize(
    min_population = min(population),
    max_unemployment = max(unemployment),
    average_income = mean(income)
  ) 
```

### 7. Summarizing by state

```{p2-7}
counties_selected %>%
  # Group by state 
  group_by(state) %>%
  # Find the total area and population
  summarize(total_area = sum(land_area), total_population = sum(population)) 

counties_selected %>%
  group_by(state) %>%
  summarize(total_area = sum(land_area),
            total_population = sum(population)) %>%
  # Add a density column
  mutate(density = total_population/total_area) %>%
  # Sort by density in descending order
  arrange(desc(density))
```

### 8. Summarizing by state and region

```{p2-8}
counties_selected %>%
  # Group and summarize to find the total population
  group_by(region, state) %>%
  summarize(total_pop = sum(population)) %>%
  
  # Calculate the average_pop and median_pop columns 
  summarize(
    average_pop = mean(total_pop),
    median_pop = median(total_pop)
  )
```

### 9. The slice_min and slice_max verbs

```{}
1. The slice_min and slice_max verbs
What if instead of aggregating each state, we wanted to find only the largest or smallest counties in each state? dplyr's slice_min and slice_max verbs allow us to extract the most extreme observations from each group.

2. slice_max()
Like summarize(), slice_max() operates on a grouped table, and returns the largest observations in each group. The function takes two arguments: the column we want to base the ordering on, and the number of observations to extract from each group, specified with the n argument. In this example, grouping by state and then calling slice_max on the population column with n equals 1 returns the county with the highest population in each state.

3. slice_max() output
This tells us, for example, that Jefferson is the county with the highest population in Alabama with a population of 659,000. Notice that it kept the other columns in this table, in this case, unemployment and income.

4. slice_min()
Similarly, slice_min() returns the smallest observations in each group. Instead of looking at the population, we could find the county with the lowest unemployment rate from each state by calling slice_min() on the unemployment column.

5. slice_min() output
The output shows that, for example, Jackson is the county with the lowest unemployment rate in the state of Colorado, with an unemployment rate of 1-point-5 percent.

6. Number of observations
We can use other values of n in our slice_min() and slice_max() calls, and get that many counties from each state. For instance, slice_max() on unemployment with n = 3 will return the three counties in each state with the highest unemployment rate. For Alabama, these turn out to be named Conecuh, Monroe, and Wilcox. The slicing verbs are often used when creating visualizations, where we may want to highlight the extreme observations on the plot. 
```

### 10. Selecting a county from each region

```{p2-10}
counties_selected %>%
  # Group by region
  group_by(region) %>%
  # Find the county with the highest percentage of people who walk to work
  slice_max(walk, n=1) 
```

### 11. Finding the lowest-income state in each region

```{p2-11}
counties_selected %>%
  group_by(region, state) %>%
  # Calculate average income
  summarize(average_income = mean(income)) %>%
  # Find the lowest income state in each region
  slice_min(average_income, n=1) 
```

### 12. Using summarize, slice_max, and count together

```{p2-12}
counties_selected %>%
  # Find the total population for each combination of state and metro
  group_by(state, metro) %>%
  summarize(total_pop = sum(population)) 

  # Extract the most populated row for each state
  slice_max(total_pop, n=1)

  # Count the states with more people in Metro or Nonmetro areas
  ungroup() %>%
  count(metro)
```

## Part 3. Selecting and Transforming Data

### 1. Selecting

```{}
1. Selecting
This chapter focuses on advanced methods of selecting and transforming columns. There are a ton of variables in the counties dataset, and we often only want to work with a subset of them.

2. Select
We've already seen that we can select the columns that we're interested in by listing them inside the select verb.

3. Select a range
We can also select a range of columns. For example, there are a series of columns containing information on how people get to work. If we wanted to select this range of columns from drive to work_at_home, we can use drive colon work_at_home.

4. Select and arrange
By selecting and arranging these columns, we find that the counties where the fewest people drive to work are located in Alaska and New York. We can see other interesting insights because we've focused in on this part of the data: in New York people mostly take transit to work, while in the small parts of Alaska, they mostly walk.

5. Contains
There are also other useful techniques for selecting columns. dplyr provides "select helpers", which are functions that specify criteria for choosing columns. We'll start with the contains function. To select all columns containing the word, "work", pass contains "work" to the select() function. Notice that we place work in quotes, unlike state and county; this is because select helpers take strings, which must be specified using quotes.

6. Starts with
We can also use starts_with to select only the columns that start with a particular prefix. We could use this to get all of the columns that begin with the word "income", which are generally related to each other. Select helpers are great for picking just the parts of a table that are relevant to the question.

7. Other helpers
dplyr provides a number of select helpers besides contains and starts_with, such as ends_with, which finds columns ending in a string, last_col, which grabs the last column, and matches, which selects columns that have a specified pattern. To discover more about select helpers, check out the dplyr select helpers documentation, using question mark-select_helpers.

8. Removing a variable
Finally, we can use select to remove variables from a table by adding a minus sign in front of the column name to remove. If we decide that the census id for each county is not very helpful, select minus census_id removes just that column.
```

### 2. Selecting columns

```{p3-2}
# Glimpse the counties table
glimpse(counties)

counties %>%
  # Select state, county, population, and industry-related columns
  select(state, county, population, professional, service, office, construction, production) %>%
  # Arrange service in descending order 
  arrange(desc(service))
```

### 3. Select helpers

```{p3-3}
counties %>%
  # Select the state, county, population, and those ending with "work"
  select(state, county, population, ends_with('work')) %>%
  # Filter for counties that have at least 50% of people engaged in public work
  filter(public_work >= 50)
```

### 4. The rename verb

```{}
1. The rename verb
Often, rather than only selecting columns, we'll sometimes want to rename the ones we already have. We'll learn a new verb to do this: the rename() verb.

2. Select columns
Let's start with a selected version of the counties dataset. Suppose we decide that the column name "unemployment" is a little ambiguous, and we'd like to rename it to unemployment_rate for clarity.

3. Rename a column
We can do this by piping into the rename verb, then specifying unemployment_rate equals unemployment. Notice that the new column name goes on the left, and the old column name goes on the right. In the result, the column's name has been changed to unemployment_rate.

4. Combine verbs
There's actually another way that to choose new names for columns: we can do it as part of select(). Take a look at this variation on select. We choose the three columns state, county, and population, but we can also specify unemployment_rate equals unemployment. This produces the same result of renaming the column: it's like select and rename in one step.

5. Compare verbs
Notice the difference between select and rename. In select we need to name all the columns you want to keep along with renaming one or more of them. With rename, we can just pick one column whose name you want to change. The verb we choose will vary depending on the analysis and the dataset.
```

### 5. Renaming a column after count

```{p3-5}
counties %>%
  # Count the number of counties in each state
  count(state) %>% 

counties %>%
  # Count the number of counties in each state
  count(state) %>%
  # Rename the n column to num_counties
  rename(num_counties = n)
```

### 6. Renaming a column as part of a select

```{p3-6}
counties %>%
  # Select state, county, and poverty as poverty_rate
  select(state, county, poverty_rate = poverty) 
```

### 7. The transmute verb

```{}

Got It!
1. The transmute verb
We've learned about the select, rename, and mutate verbs for transforming data, but now we'll learn a fourth one: transmute().

2. Transmute
Transmute is like a combination of select and mutate: it returns a subset of the columns like select, but it can also transform and change the columns, like mutate, at the same time.

3. Select and calculate
For example, suppose we want only one piece of information about each state and county: the fraction of the population made up of men. We could do transmute, state, county, and fraction-underscore-men equals men divided by population. Notice that, like select, you dropped all other columns and only kept these three. We didn't even keep the men or population columns that we used to calculate fraction_men. But, unlike select, we were able to do a calculation at the same time: creating a new column called fraction_men. This saves some effort compared to doing both a mutate and a select.

4. Select and calculate
As another example, we've already worked with the unemployment column that contains the unemployment rate. We could calculate the total number, not the percentage, of unemployed people in the county, and keep the population column as well. We can calculate the number of unemployed people by multiplying the unemployment rate by the population. The transmute() verb gives us control of what variables to keep, what new variables to calculate, and what to drop.

5. Summary
By now, we've learned four verbs to add, remove, and change variables in a table: select(), rename(), transmute(), and mutate().

6. Summary
Along the top row, select() and rename() don't change the values in the columns at all: they just change which are kept in the table and what they're called.

7. Summary
Along the bottom, transmute() and mutate() can be used to calculate new values.

8. Summary
On the left, what select() and transmute() have in common is that they only keep the columns that are specified.

9. Summary
On the right, rename() and mutate() keep all the columns that are already in the table, they just change the ones that are specified.

10. Summary
So, based on which variables you want to keep, drop, rename, or change, we can choose among these four verbs. 
```

### 8. Choosing among verbs

```{}
Which of the following verbs would you use to calculate new columns while dropping other columns?
A. select
B. mutate
-> C. transmute
D. rename
```

### 9. Using transmute

```{p3-9}
counties %>%
  # Keep the state, county, and populations columns, and add a density column
  transmute(state, county, population, density = population/land_area) %>%
  # Filter for counties with a population greater than one million 
  filter(population > 1000000) %>%
  # Sort density in ascending order 
  arrange(density) 
```

### 10. Matching verbs to their definitions

```{}
rename: leaves the columns you don't mention alone; doesn't allow you to calculate or change values
transmute: must mention all the columns you keep; allows you to calculate or change values
mutate: leaves the columns you don't mention alone; allows you to calculate or change values
```

### 11. Choosing among the four verbs

```{p3-11}
# Change the name of the unemployment column
counties %>%
  rename(unemployment_rate = unemployment)

# Keep the state and county columns, and the columns containing poverty
counties %>%
  select(state, county, contains("poverty"))

# Calculate the fraction_women column without dropping the other columns
counties %>%
  mutate(fraction_women = women / population)

# Keep only the state, county, and employment_rate columns
counties %>%
  transmute(state, county, employment_rate = employed / population) 
```

## Part 4. Case Study: The babynames Dataset

### 1. The babynames data

```{}
1. The babynames data
So far in this course, we've been using the counties dataset, which contains US census data at a county level. In this chapter, we're going to analyze a new dataset, one representing the names of babies born in the United States each year.

2. The babynames data
This will allow us to both practice what we've already learned on a new dataset, and learn a few new dplyr tools for exploring data. We'll also learn a bit about the ggplot2 package, which is the Tidyverse visualization package. In the babynames table, each observation, or row, represents one combination of a year and a name, like 1880 and John. The third variable, number, represents the number of babies born in the United States with that name. For example, in 1880 there were 102 babies born named Aaron.

3. Frequency of a name
We can learn a lot from this table using some of the verbs we learned earlier. For example, suppose you want to find the frequency of the name Amy in each year. We could filter where name equals Amy. Unless your first name is very rare in the United States, you can probably find your own name in the table as well. We can work with this output as a table like this, but it's probably more useful to turn it into a line graph, so we can see how the frequency varies over time.

4. Amy plot
We'll visualize the data using the ggplot2 package, which we can load with library(ggplot2). There are three parts to a ggplot2 plot: the data, the aesthetics, and the layers. The data, in this case, is the filtered version of babynames, babynames_filtered. We call the ggplot() function to begin the plot, and pass the data as the first argument, and the aethetics as the second. The aesthetics are specified using the aes() function, and inside, we specify what we would like to display on each axis: year on the x-axis and number on the y-axis. To tell ggplot that we want a line plot, we must add a layer,

5. Amy plot
which we do by including a plus-sign after the ggplot() call, and calling the geom_line function, which maps the data onto a line plot.

6. Amy plot
Based on this, we can see that many babies born in the 70s and 80s were named Amy, but relatively few today. Notice how nicely dplyr and ggplot2 worked together to draw these insights.

7. Filter for multiple names
Besides filtering for just one name, you could filter for multiple names, using the percent-in-percent operator. You could search for the names Amy and Christopher by doing percent-in-percent, then providing a vector, with c, containing Amy and Christopher. In the exercises, you'll see how this can be used to make a graph of multiple names.

8. When was each name most common?
As one more use of dplyr, recall that you can use the slice_max verb, along with group_by, to find the year in which each name was most common. For instance, this tells us that the year when the most babies were named Garfield was 1880. In the exercises, you'll see that you could use a similar approach to find the most common name from every year.
```

### 2. Filtering and arranging for one year

```{p4-2}
babynames %>%
  # Filter for the year 1990
  filter(year == 1990) %>%
  # Sort the number column in descending order 
  arrange(desc(number))
```

### 3. Finding the most popular names each year

```{p4-3}
babynames %>%
  # Find the most common name in each year
  group_by(year) %>%
  slice_max(number, n=1)
```

### 4. Visualizing names with ggplot2

```{p4-4}
selected_names <- babynames %>%
  # Filter for the names Steven, Thomas, and Matthew 
  filter(name %in% c("Steven", "Thomas", "Matthew"))

# Plot the names using a different color for each name
ggplot(selected_names, aes(x = year, y = number, color = name)) +
  geom_line()
```

### 5. Grouped mutates

```{}
1. Grouped mutates
Previously, we learned about the babynames data, and how we can use it to answer questions about specific names or years.

2. babynames graph
This graph shows the frequency of three different baby names over time. The y-axis represents the number of people born in each year with the name Matthew, Steven, or Thomas. But remember that a different total number of babies are born in each year, and what we're interested in isn't exactly the number who are born. Rather, we're interested in what percentage of people born in that year have that name. To calculate that, we'll need to work with the total number of people born in each year. To do that, you'll learn how to do a grouped mutate.

3. Review: group_by() and summarize()
Remember how group_by and summarize work. We could first tell dplyr to group by the year column, then summarize to calculate the sum of the number column. This gets a table with one row for every year. This is already pretty useful by itself. But we want to get the total number of people born in each year alongside the original data. For that, change the summarize to a mutate.

4. Combining group_by() and mutate()
We call this a grouped mutate. Just like group_by and summarize work well together, group_by and mutate are a great pair. The group_by tells dplyr that we only want to add up within each year. Then, the mutate creates a new column called year_total, with the total number of people born in that year in this dataset. Notice from the header that the table is still grouped by year, which could affect other verbs we want to use in the future. In particular, it can make other mutates or filters slower to run, especially if there are a lot of groups in the table.

5. ungroup()
Therefore, it's good practice to use one more dplyr verb, ungroup(), since we're done with grouped calculations.

6. Add the fraction column
Now that we have the total in each year, we can calculate the fraction of people born in each year that have each name. This is number divided by year_total. So we do one more mutate to add that column. We can now see the fraction of babies in 1880 that received each name. This could make your graphs more interpretable, since they'll be looking at the fraction of babies born in each year that have a particular name.

7. Comparing visualizations
Remember how you graphed the number of babies born in each year. If you graphed this fraction instead, you'd have seen a very different visualization! This is because the dataset includes relatively few babies from the 1800s and early 1900s. Thanks to our grouped mutate, we have a better visualization of the relative popularity of the name in each year. 
```

### 6. Finding the year each name is most common

```{p4-6}
# Calculate the fraction of people born each year with the same name
babynames %>%
  group_by(year) %>%
  mutate(year_total = sum(number)) %>%
  ungroup() %>%
  mutate(fraction = number / year_total) %>%

# Find the year each name is most common
  group_by(name) %>%
  slice_max(fraction, n = 1)
```

### 7. Adding the total and maximum for each name

```{p4-7}
babynames %>%
  # Add columns name_total and name_max for each name
  group_by(name) %>%
  mutate(
    name_total = sum(number),
    name_max = max(number)
  )

babynames %>%
  # Add columns name_total and name_max for each name
  group_by(name) %>%
  mutate(name_total = sum(number),
         name_max = max(number)) %>%
  # Ungroup the table 
  ungroup() %>%
  # Add the fraction_max column containing the number by the name maximum 
  mutate(fraction_max = number/name_max) 
```

### 8. Visualizing the normalized change in popularity

```{p4-8}
names_filtered <- names_normalized %>%
  # Filter for the names Steven, Thomas, and Matthew
  filter(name %in% c("Steven", "Thomas", "Matthew"))

# Visualize these names over time
ggplot(names_filtered, aes(x=year, y=fraction_max, color=name)) +
  geom_line()
```

### 9. Window functions

```{}
1. Window functions
Throughout this chapter, we've looked at trends of baby names over time in the United States.

2. babynames graph
We've made visualizations, and discovered a few names that have gone through major changes over time. But what if you want to look at the biggest changes within each name? To do this, we'd have to find differences between each pair of consecutive years.

3. Window function
To do this, we'll introduce the last new concept of this course: the window function. A window function takes a vector, and returns another vector of the same length. You'll be learning to use the lag() function. For example, suppose we had a vector of 1, 3, 6, and 14. We can lag this vector, which means moving each item to the right by one. Now the first item is NA, meaning it's missing, but it's followed by 1, 3, and 6: the item just prior to it in the original vector.

4. Compare consecutive steps
Now, why is this useful? Because by lining up each item in the vector with the item directly before it, we can compare consecutive steps and calculate the changes. With v minus lag(v), we're asking "What is each value once we've subtracted the previous one?"

5. Changes in popularity of a name
Now that we know how to calculate the difference between consecutive values in a vector, we can use that in a grouped mutate to find the changes in the popularity of one name in consecutive years. Consider the babynames dataset. We'll use the same code as we did in the last lesson to create a table with the babynames fraction.

6. Matthew
Let's start by picking a name, like Matthew, and filtering for it. Then we arrange in ascending order of year. We can see the fraction of babies born each year that are named Matthew. We can also compare between years. Notice that the fraction of babies named Matthew started around point-0005, then went down to point-0004.

7. Matthew over time
To quantify that, we could use a mutate with the lag window function. We want to take each fraction, and subtract the "lagged" fraction, with fraction minus lag(fraction). Notice that the first observation is missing a difference, because there is no previous year. After that, we can see whether Matthew went up or down each year.

8. Biggest jump in popularity
What if we wanted to know the biggest jump that the name Matthew took in popularity? We could sort in descending order of the difference column, and see that the biggest jumps, when Matthew got much more popular, were in 1975 and 1970.

9. Changes within every name
Now what if instead of looking at one name, we wanted to look at the changes within every name? We'll need to do this as a grouped mutate, as you learned in the last lesson, first grouping by name before calculating the difference between each year. This ensures we won't include differences between two different names. 
```

### 10. Using ratios to describe the frequency of a name

```{p4-10}
babynames_fraction %>%
  # Arrange the data in order of name, then year 
  arrange(name, year) %>%
  # Group the data by name
  group_by(name) %>%
  # Add a ratio column that contains the ratio of fraction between each year 
  mutate(ratio = fraction/lag(fraction)) 
```

### 11. Biggest jumps in a name

```{p4-11}
babynames_ratios_filtered %>%
  # Extract the largest ratio from each name 
  slice_max(ratio, n = 1) %>%
  # Sort the ratio column in descending order 
  arrange(desc(ratio)) %>%
  # Filter for fractions greater than or equal to 0.001
  filter(fraction >= 0.001) 
```

### 12. Summary 

```{}
Overview
1. Congratulations!
Congratulations! You've made it to the end of the course.

2. Summary
In this course, you've learned how to transform data with the dplyr package. You reviewed the select, filter, mutate, and arrange verbs for transforming data. You mastered the count verb, and learned the powerful group_by and summarize pattern for aggregating data.

3. Verbs table
You learned four verbs you can use for adding, removing, and changing variables in a table: select, rename, transmute, and mutate.

4. babynames data
You also applied many of these tools to a new babynames dataset, and gained experience with grouped mutates and window functions.
```
